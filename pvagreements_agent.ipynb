{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52af46c1-aa83-4ee0-a143-74bbdfb4210e",
   "metadata": {},
   "source": [
    "# Import packages and load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c1336d-adef-4d74-8d6d-f415a25261e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import base64\n",
    "import time\n",
    "import pandas as pd\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from vertexai.generative_models import (GenerativeModel,\n",
    "                                        GenerationResponse,\n",
    "                                        Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b6e8ce-5399-401c-8dd6-19c1a2885eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VertexAI\n",
    "credentials = service_account.Credentials.from_service_account_file(\"service-account.json\")\n",
    "\n",
    "aiplatform.init(project = 'project-id',\n",
    "                credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6013a6d2-b515-4c62-819b-2b34dfea2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test documents that are classified as 'No need for additional anaysis'\n",
    "no_pva_path = \"C:/Users/llm_agent_pva/Docs/NO_PVA\"\n",
    "\n",
    "# Get the test documents that are classified as 'Yes need for additional anaysis'\n",
    "yes_pva_path = \"C:/Users/llm_agent_pva/Docs/YES_PVA\"\n",
    "\n",
    "no_pva_docs = os.listdir(no_pva_path)\n",
    "yes_pva_docs = os.listdir(yes_pva_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61740e2-68c8-4a80-82da-1d5254beb2e4",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb54da0-53d9-4df8-9846-77785790e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for the summary of the document for PVA_needed \n",
    "parties = \"\"\"Extract the parties involved in this contract. Return the response in the form of a dictionary with the given format.\n",
    "Format: {\"parties\": <parties>}\"\"\"\n",
    "\n",
    "effective_date = \"\"\"Extract the effective date from this contract and pressent it in a dictionary format as shown below.\n",
    "Date should be formatted in Day-Month-Year.\n",
    "\n",
    "Format: {\"effective_date\": <Response>}\"\"\"\n",
    "\n",
    "territory = \"\"\"Extract the territory details from this contract and present the answer in the below format.\n",
    "Format: {\"territory\": <territory>}\"\"\"\n",
    "\n",
    "recitals = \"\"\"Extract the recitals from this contract. Return the response in the form of a dictionary with the given format.\n",
    "Format: {\"recitals\": <recitals>}\"\"\"\n",
    "\n",
    "local_global = \"\"\"You are a legal expert. Read the contract given below and check if the distributor has rights to distribute in one territory or multiple territories.\n",
    "Rules:\n",
    "    - Determine the number of countries the distributor is responsible for.\n",
    "    - If the partner is resopnsible for distributing in only one country, consider it as a 'Local' or else, consider it as 'Global'.\n",
    "    - Apart from determining if is 'Local' or 'Global', justify your answer in a single paragraph.\n",
    "    \n",
    "Format: {\"local_global\": <answer>, \"local_global_reason\": <justification>}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7c16af-6777-4ab7-b424-19c39ce5f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for the PVA needed or not analysis\n",
    "is_commercial = \"\"\"You are a legal expert. Read the contract given below and check if the contract is related 'Commercial' or 'Service'. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - Label the contract as 'Commercial' if the contract is related to product supply, sales and distribution, product pricing, payment purchase of products, quantity of products or delivery of products.\n",
    "    - Label the contract as 'Service' otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"contract_type\": <response>}\"\"\"\n",
    "\n",
    "distribution_in_out = \"\"\"You are a legal expert. Read the contract given below and determine if {main_company} is giving out the distribution rights or it is taking the distribution rights. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - If {main_company} is giving out the distribution rights, return the answer as \"Distribution-Out\".\n",
    "    - Return the answer as \"Distribution-In\" otherwise.\n",
    "    - Use strictly only these rules to determine your response.\n",
    "    \n",
    "Format: {\"distribution_type\": <distribution type>}\"\"\"\n",
    "\n",
    "mah_owner = \"\"\"You are a legal expert. Read the contract given below and check if there is a transfer of Marketing Authorization (MAH) Rights to other parties. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - Determine the partner of {main_company}.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for registering the product with regulatory body.\n",
    "    - Mark the contract as \"Partner\" if Janssen is transferring the marketing authorization holder rights to the partner in the distribution territory.\n",
    "    - Mark the contract as \"{main_company}\" otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"mah_owner\": <mah owner>}\"\"\"\n",
    "\n",
    "hcp_poc = \"\"\"You are a legal expert. Read the contract given below and determine if {main_company} is in direct contact with healthcare professionals (HCP).\n",
    "Return the response in the form of a dictionary with the given format.\n",
    "Return your answer in the form of \"{main_company}\" or \"Partner\".\n",
    "\n",
    "Rules:\n",
    "    - Determine the partner of {main_company}.\n",
    "    - Mark the contract as \"{main_company}\" if the partner is responsible for holding discussions with pharmacies, hospitals, or doctors, if is directly communicating with patients, or if is responsible for collecting and reporting adverse events information.\n",
    "    - Mark the contract as \"Partner\" otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"hcp_poc\": <hcp poc>}\"\"\"\n",
    "\n",
    "partner_packaging = \"\"\"You are a legal expert. Read the contract given below and check if the contract is related to {main_company} partner's responsibility towards packaging, ownership of packaging, labeling, and trademarks. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - Determine the partner of {main_company}.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for packaging.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for owning the packaging.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for labeling, trademarks, and/or leaflets.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for including their details in the packaging.\n",
    "    - Mark the contract as \"{main_company}\" otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"packaging_owner\": <owner>}\"\"\"\n",
    "\n",
    "reg_poc = \"\"\"You are a legal expert. Read the contract given below and determine if {main_company} is responsible for regulatory filing and communication. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - Determine the partner of {main_company}.\n",
    "    - Mark the contract as \"Partner\" if the partner is responsible for the regulatory filing and regulatory communication.\n",
    "    - Mark the contract as \"{main_company}\" otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"regulatory_poc\": <regulatory poc>}\"\"\"\n",
    "\n",
    "pva_needed = \"\"\"You are a legal advisor. Use the content given below and identify if the partner is responsible for any of the obligations mentioned on the following rules. Return the response in the form of a dictionary with the given format.\n",
    "Rules:\n",
    "    - ONLY respond with \"Yes\" or \"No\".\n",
    "    - Mark the contract as \"Yes\" if packaging_owner is the partner.\n",
    "    - Mark the contract as \"Yes\" if regulatory_poc is the partner.\n",
    "    - Mark the contract as \"Yes\" if hcp_poc is the partner.\n",
    "    - Mark the contract as \"No\" otherwise.\n",
    "    - Use strictly only these rules to determine the label of the contract.\n",
    "    \n",
    "Format: {\"pva_needed\": <\"Yes\" or \"No\">}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badd294c-5982-4673-8d27-95015cd398e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompts = [parties, effective_date, territory, recitals, local_global]\n",
    "pva_prompts = [is_commercial, distribution_in_out, mah_owner, hcp_poc, partner_packaging, reg_poc, pva_needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12dfd5e-44e8-432c-9a07-b93951bc6671",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a1b445-ccde-489a-88fe-abaee3e69b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_calls(response:GenerationResponse) -> List[Dict]:\n",
    "    function_calls = []\n",
    "\n",
    "    if response.candidates[0].function_calls:\n",
    "        for function_call in response.candidates[0].function_calls:\n",
    "            function_call_dict = {function_call.name: {}}\n",
    "            \n",
    "            for key,value in function_call.args.items():\n",
    "                function_call_dict[function_call.name][key] = value\n",
    "\n",
    "            function_calls.append(function_call_dict)\n",
    "\n",
    "    return function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e779d0d-792c-4827-b6e4-14e74a49166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_call_gemini(prompt, temp=0, max_tkn=8192, p=0.95):\n",
    "    \n",
    "    gemini = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "    safety_settings = {generative_models.HarmCategory.HARM_CATEGORY_UNSPECIFIED: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                       generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                       generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                       generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                       generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE}\n",
    "    \n",
    "    ans = await gemini.generate_content_async(prompt,\n",
    "                                              generation_config = {\"temperature\": temp,\n",
    "                                                                   \"max_output_tokens\": max_tkn,\n",
    "                                                                   \"top_p\": p},\n",
    "                                              safety_settings = safety_settings)\n",
    "    in_tkns = ans.usage_metadata.prompt_token_count\n",
    "    out_tkns = ans.usage_metadata.candidates_token_count\n",
    "    # print(in_tkns, out_tkns)\n",
    "    return ans.text, in_tkns, out_tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a21687-8a70-4b92-b4db-a1d34a7ada2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs(paths):\n",
    "    docs = []\n",
    "\n",
    "    for path in paths:\n",
    "        \n",
    "        # Encode the document\n",
    "        with open(path, \"rb\") as pdf_file:\n",
    "            encoded_doc = base64.b64encode(pdf_file.read())\n",
    "\n",
    "        # Create the VertexAI document\n",
    "        doc = Part.from_data(mime_type = \"application/pdf\",\n",
    "                             data = base64.b64decode(encoded_doc))\n",
    "\n",
    "        # Save the doc on the list\n",
    "        docs.append(doc)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbc4273-3493-43b1-a5b4-dbaa5b443479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_cost(in_tkns, out_tkns, model=\"gemini-1.5-flash-001\"):\n",
    "    # The costs are for every 1k characters (or 250 tokens) as described in https://cloud.google.com/vertex-ai/generative-ai/pricing\n",
    "    if model == \"gemini-1.5-flash-001\":\n",
    "        llm = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "        cost_in = 0.000125\n",
    "        cost_out = 0.000375\n",
    "    # Assuming it's Gemini 1.5 Pro\n",
    "    else:\n",
    "        llm = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "        cost_in = 0.00125\n",
    "        cost_out = 0.00375\n",
    "\n",
    "    out_cost = (cost_out * out_tkns) / 250\n",
    "    in_cost = (cost_in * in_tkns) / 250\n",
    "\n",
    "    total_tkns = in_tkns + out_tkns\n",
    "    total_cost = in_cost + out_cost\n",
    "    return total_tkns, total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a5810b-5711-4a4a-b493-cb33b7c8b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(ans):\n",
    "    out = {}\n",
    "    \n",
    "    if \"```\" in ans:\n",
    "        ans = ans.split(\"\\n{\", 1)[1].rsplit(\"}\\n\", 1)[0]\n",
    "\n",
    "    key_value = [''.join(i.replace('\"', '', 1).rsplit('\"', 1)) for i in ans.split(\": \", 1)]\n",
    "\n",
    "    if key_value[0] == \"local_global\":\n",
    "        key_value_second = key_value[1].split('\", ')\n",
    "        out[key_value[0].replace(\"{\", '')] = key_value_second[0].replace(\"}\", '')\n",
    "        key_value_second = [''.join(i.replace('\"', '', 1).rsplit('\"', 1)) for i in key_value_second[1].split(\": \", 1)]\n",
    "        out[key_value_second[0].replace(\"{\", '')] = key_value_second[1].replace(\"}\", '')\n",
    "    else:\n",
    "        out[key_value[0].replace(\"{\", '')] = key_value[1].replace(\"}\", '')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8753b805-997f-4629-8e57-4a65ed9aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_llm_outs(outs):\n",
    "    ans = {}\n",
    "\n",
    "    for out in outs:\n",
    "        # Parse into a dictionary\n",
    "        out_json = format_json(out)\n",
    "    \n",
    "        # Include all keys and values into the generic final answer dictionary\n",
    "        for key,value in out_json.items():\n",
    "            ans[key] = value\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50aed66-56db-457c-8688-a33c1f533c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retry_llm_outs(doc, max_tries=3):\n",
    "    attempts = 1\n",
    "    done = False\n",
    "\n",
    "    while (max_tries >= attempts) and (not done):\n",
    "        try:\n",
    "            start = time.time()\n",
    "            outs = await asyncio.gather(*[async_call_gemini([prompt] + doc) for prompt in (summary_prompts + pva_prompts)])\n",
    "            end = time.time() - start\n",
    "\n",
    "            answers = [i[0] for i in outs]\n",
    "            in_tkns = sum([i[1] for i in outs])\n",
    "            out_tkns = sum([i[2] for i in outs])\n",
    "            done = True\n",
    "        except:\n",
    "            print(f\"\\t> Trying again. Waiting for {60*attempts} seconds...\")\n",
    "            time.sleep(60*attempts)\n",
    "            attempts += 1\n",
    "\n",
    "    return answers, in_tkns, out_tkns, end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8a762-fa2e-49cc-b9f5-e0654f4dfda4",
   "metadata": {},
   "source": [
    "# Main tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb94e87-cf17-442b-95a7-fc73db3f2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def pva_needed(path:str):\n",
    "    \"\"\"Run initial document analysis to determine if a PV Agreement is needed or not.\n",
    "    \n",
    "    Input:\n",
    "        path: The path for the PDF file that will be analyzed.\"\"\"\n",
    "\n",
    "    # Prepare the document to be given to the LLM\n",
    "    print(\"Parsing documents...\")\n",
    "    doc = create_docs([path])\n",
    "    print(\"\\t> Documents done!\")\n",
    "    \n",
    "    # Run the prompts on the document\n",
    "    print(\"Running prompts...\")\n",
    "    outs, in_tkns, out_tkns, end = await retry_llm_outs(doc)\n",
    "    print(\"\\t> Prompts executed!\")\n",
    "\n",
    "    # Format all the answer into a single dictionary\n",
    "    ans = format_llm_outs(outs)\n",
    "    \n",
    "    # Get the number of tokens and cost for every input of the LLM calls\n",
    "    print(\"Getting cost of inputs...\")\n",
    "    total_tkns, total_cost = get_gemini_cost(in_tkns, out_tkns)\n",
    "    print(\"\\t> Costs measured!\")\n",
    "\n",
    "    # Add the costs and tokens to the final answer\n",
    "    ans[\"total_tokens\"] = total_tkns\n",
    "    ans[\"llm_cost\"] = total_cost\n",
    "    ans[\"execution_time\"] = end\n",
    "    \n",
    "    # print(out_tkns)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe1e09-6deb-4f0e-83ac-d1d596755104",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a199f-0f85-4a38-a67e-c43c389de635",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/test_contract.pdf\"\n",
    "await pva_needed(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679224f7-14b6-4636-b2ae-d737cd0b19bf",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f9240-e014-4642-bac6-014216ef5f6b",
   "metadata": {},
   "source": [
    "## Classifying if PVA is needed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a012da-088d-4568-8bce-2c7c3a65ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file_path = \"gemini_pv_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0341c8-494b-4768-a0f6-f539c163fa6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file 8 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 9 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 10 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 11 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 12 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 13 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 14 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 15 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 16 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 17 of 17:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "\n",
      "Documents completed!\n"
     ]
    }
   ],
   "source": [
    "# Get the data from the NO_PVA files\n",
    "for i in range(7, len(no_pva_docs)):\n",
    "    print(f\"Checking file {i+1} of {len(no_pva_docs)}:\")\n",
    "\n",
    "    try:\n",
    "        llm_outs = await pva_needed(no_pva_path + '/' + no_pva_docs[i])\n",
    "\n",
    "        llm_outs[\"file_name\"] = no_pva_docs[i].split(\".\")[0]\n",
    "        llm_outs[\"pva_needed_ground_truth\"] = \"No\"\n",
    "\n",
    "        # Create the dataframe and store on the csv file\n",
    "        df = pd.DataFrame.from_dict([llm_outs])\n",
    "        df.to_csv(res_file_path,\n",
    "                  mode = 'a',\n",
    "                  index = False,\n",
    "                  header = False)\n",
    "    except:\n",
    "        print(f\"Couldn't process file {no_pva_docs[i]}\")\n",
    "    \n",
    "print(\"\\nDocuments completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b5d1e-772c-4aa8-9e7d-5175b397c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fullPDF = pd.read_csv(res_file_path)\n",
    "df_fullPDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa658be5-0623-45ad-a6c0-6f0aa00c7b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file 1 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 2 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 3 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 4 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 5 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 6 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 7 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 8 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 9 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 10 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 11 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 12 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 13 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 14 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 15 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 16 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 17 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 18 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 19 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 20 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 21 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 22 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 23 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 24 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 25 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 26 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 27 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 28 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 29 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 30 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 31 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 32 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 33 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 34 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 35 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "Checking file 36 of 36:\n",
      "Parsing documents...\n",
      "\t> Documents done!\n",
      "Running prompts...\n",
      "\t> Prompts executed!\n",
      "Getting cost of inputs...\n",
      "\t> Input costs measured!\n",
      "\n",
      "Documents completed!\n"
     ]
    }
   ],
   "source": [
    "# Get the data from the YES_PVA files\n",
    "for i in range(len(yes_pva_docs)):\n",
    "    print(f\"Checking file {i+1} of {len(yes_pva_docs)}:\")\n",
    "\n",
    "    try:\n",
    "        llm_outs = await pva_needed(yes_pva_path + '/' + yes_pva_docs[i])\n",
    "\n",
    "        llm_outs[\"file_name\"] = yes_pva_docs[i].split(\".\")[0]\n",
    "        llm_outs[\"pva_needed_ground_truth\"] = \"Yes\"\n",
    "\n",
    "        # Create the dataframe and store on the csv file\n",
    "        df = pd.DataFrame.from_dict([llm_outs])\n",
    "        df.to_csv(res_file_path,\n",
    "                  mode = 'a',\n",
    "                  index = False,\n",
    "                  header = False)\n",
    "    except:\n",
    "        print(f\"Couldn't process file {yes_pva_docs[i]}\")\n",
    "\n",
    "print(\"\\nDocuments completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fullPDF = pd.read_csv(res_file_path)\n",
    "df_fullPDF.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
